{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class LunakDense:\n",
    "    def __init__(self, units, activation, input_dim, init, use_bias=False, seed=None):\n",
    "        self.units = units\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        if activation == 'sigmoid':\n",
    "            self.activation_function = self.sigmoid\n",
    "        else:\n",
    "            print('Activation function not supported')\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        if init == 'uniform':\n",
    "            self.weight_matrix = np.random.uniform(-0.05, 0.05, size=(self.units, input_dim)) \n",
    "            print(self.weight_matrix)\n",
    "        elif init == 'random':\n",
    "            self.weight_matrix = np.random.random(size=(self.units, input_dim))\n",
    "        else:\n",
    "            print('Init function not supported')\n",
    "        \n",
    "        self.delta_weight_matrix_before = np.zeros((self.units, input_dim))\n",
    "        self.delta_weight_matrix = np.zeros((self.units, input_dim))\n",
    "        \n",
    "        self.use_bias = use_bias\n",
    "        if self.use_bias:\n",
    "            bias = np.zeros((units, 1))\n",
    "            self.weight_matrix = np.hstack((self.weight_matrix, bias))\n",
    "            self.delta_weight_matrix_before = np.hstack((self.delta_weight_matrix_before, np.zeros((units, 1))))\n",
    "            self.delta_weight_matrix = np.hstack((self.delta_weight_matrix, np.zeros((units, 1))))\n",
    "            \n",
    "    def calculate_sigma(self, input_list):\n",
    "        if self.use_bias:\n",
    "            input_list = np.append(input_list, 1)\n",
    "        \n",
    "        result_list = np.array([])\n",
    "        for weight_neuron in self.weight_matrix:\n",
    "            result_list = np.append(result_list, np.dot(weight_neuron, input_list))\n",
    "        return np.array(result_list)\n",
    "    \n",
    "    def calculate_output(self, input_list):\n",
    "        output_list = np.array([])\n",
    "        for sigma_neuron in self.calculate_sigma(input_list):\n",
    "            output_list = np.append(output_list, self.activation_function(sigma_neuron))\n",
    "        self.output_list = output_list\n",
    "        return output_list.copy()\n",
    "    \n",
    "    def calculate_local_gradient_output_layer(self, target_list):\n",
    "        \"\"\"\n",
    "        Use this if the layer is output layer\n",
    "        \"\"\"\n",
    "        result_list = np.array([])\n",
    "        for index, output in enumerate(self.output_list):\n",
    "            local_gradient = output * (1 - output) * (target_list[index] - output)\n",
    "            result_list = np.append(result_list, local_gradient)  \n",
    "        self.local_gradient = result_list\n",
    "        return result_list.copy()\n",
    "    \n",
    "    def calculate_local_gradient_hidden_layer(self, local_gradient_output_list, output_layer_weight_matrix):\n",
    "        \"\"\"\n",
    "        Use this if the layer is hidden layer\n",
    "        \"\"\"\n",
    "        result_list = np.array([])\n",
    "        for index, output in enumerate(self.output_list):\n",
    "            sigma_local_gradient_output = 0\n",
    "            for unit_number, local_gradient in enumerate(local_gradient_output_list):\n",
    "                sigma_local_gradient_output += output_layer_weight_matrix[unit_number][index] * local_gradient\n",
    "            error_hidden = output * (1 - output) * sigma_local_gradient_output\n",
    "            result_list = np.append(result_list, error_hidden)\n",
    "        self.local_gradient = result_list\n",
    "        return result_list.copy()\n",
    "    \n",
    "    def update_delta_weight(self, lr, input_list, momentum=None):\n",
    "        \"\"\"\n",
    "        Function to update delta weight\n",
    "        \"\"\"\n",
    "        if self.use_bias:\n",
    "            input_list = np.append(input_list, 1)\n",
    "        if momentum == None:\n",
    "            for j, unit in enumerate(self.weight_matrix): #j  \n",
    "                for i, source in enumerate(unit): #i\n",
    "                    delta_weight = lr * self.local_gradient[j] * input_list[i]\n",
    "#                     new_weight = source + delta_weight\n",
    "#                     self.weight_matrix[j][i] = new_weight\n",
    "                    self.delta_weight_matrix[j][i] = delta_weight.copy()\n",
    "        else:\n",
    "            for j, unit in enumerate(self.weight_matrix): #j  \n",
    "                for i, source in enumerate(unit): #i\n",
    "                    delta_weight = lr * self.local_gradient[j] * input_list[i] + momentum * self.delta_weight_matrix_before[j][i]\n",
    "                    \n",
    "                    # Update Delta Weight\n",
    "                    self.delta_weight_matrix_before[j][i] = delta_weight.copy()\n",
    "                    \n",
    "#                     new_weight = source + delta_weight\n",
    "#                     self.weight_matrix[j][i] = new_weight\n",
    "            \n",
    "            # Copy Last Update of Weight Matrix Before (Equal to Last Weight Matrix)\n",
    "            for j, unit in enumerate(self.delta_weight_matrix_before):\n",
    "                for i, source in enumerate(unit):\n",
    "                    self.delta_weight_matrix[j][i] = self.delta_weight_matrix_before[j][i].copy()\n",
    "            \n",
    "    def update_weight(self):\n",
    "        \"\"\"\n",
    "        Function to update weight\n",
    "        \"\"\"\n",
    "        for j, unit in enumerate(self.delta_weight_matrix_before):\n",
    "            for i, source in enumerate(unit):\n",
    "                self.weight_matrix[j][i] += self.delta_weight_matrix[j][i]\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.40744413, 2.45737928, 2.68872129])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "layer = LunakDense(3, 'sigmoid', 2, 'uniform', True)\n",
    "layer.calculate_sigma([3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9173932 , 0.92109941, 0.93635782])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.calculate_output([3, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54239794, 0.58904043])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_hidden = LunakDense(2, 'sigmoid', 2, 'uniform', True)\n",
    "layer_hidden.weight_matrix = np.array([[-0.2, 0.1, 0.1], [-0.1, 0.3, 0.1]])\n",
    "\n",
    "layer_hidden.calculate_output([0.1, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Calculate Local Gradient Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00329161, 0.00481495])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_hidden_output = LunakDense(2, 'sigmoid', 2, 'uniform', True)\n",
    "layer_hidden_output.output_list = [0.542, 0.589]\n",
    "layer_hidden_output.calculate_local_gradient_hidden_layer([0.0663], [[0.2, 0.3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Calculate Local Gradient Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06627076])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_error_output = LunakDense(1, 'sigmoid', 2, 'uniform', True)\n",
    "layer_error_output.output_list = [0.619]\n",
    "layer_error_output.calculate_local_gradient_output_layer([0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Update Weight Momentum 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.3 0.2]]\n",
      "[[0.2 0.3 0.2]]\n",
      "[[0.00900365 0.00979267 0.016595  ]]\n",
      "[[0.20900365 0.30979267 0.216595  ]]\n"
     ]
    }
   ],
   "source": [
    "layer_test_update_weight = LunakDense(1, 'sigmoid', 2, 'uniform', True)\n",
    "layer_test_update_weight.weight_matrix = np.array([[0.2, 0.3, 0.2]])\n",
    "\n",
    "layer_test_update_weight.delta_weight_matrix_before = np.array([[0.2, 0.3, 0.2]])\n",
    "print(layer_test_update_weight.weight_matrix)\n",
    "print(layer_test_update_weight.delta_weight_matrix_before)\n",
    "\n",
    "layer_test_update_weight.local_gradient = [0.0663]\n",
    "layer_test_update_weight.update_delta_weight(0.25, [0.542, 0.589], 0.0001)\n",
    "layer_test_update_weight.update_weight()\n",
    "print(layer_test_update_weight.delta_weight_matrix_before)\n",
    "print(layer_test_update_weight.weight_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Update Weight Momentum 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.2  0.1  0.1]\n",
      " [-0.1  0.3  0.1]]\n",
      "[[-0.2  0.1  0.1]\n",
      " [-0.1  0.3  0.1]]\n",
      "[[6.2500e-05 7.5250e-04 8.3500e-04]\n",
      " [1.1250e-04 1.1325e-03 1.2350e-03]]\n",
      "[[-0.1999375  0.1007525  0.100835 ]\n",
      " [-0.0998875  0.3011325  0.101235 ]]\n"
     ]
    }
   ],
   "source": [
    "layer_test_update_weight2 = LunakDense(2, 'sigmoid', 2, 'uniform', True)\n",
    "layer_test_update_weight2.weight_matrix = np.array([[-0.2, 0.1, 0.1], [-0.1, 0.3, 0.1]])\n",
    "\n",
    "layer_test_update_weight2.delta_weight_matrix_before = np.array([[-0.2, 0.1, 0.1], [-0.1, 0.3, 0.1]])\n",
    "print(layer_test_update_weight2.weight_matrix)\n",
    "print(layer_test_update_weight2.delta_weight_matrix_before)\n",
    "\n",
    "layer_test_update_weight2.local_gradient = [0.0033, 0.0049]\n",
    "layer_test_update_weight2.update_delta_weight(0.25, [0.1, 0.9], 0.0001)\n",
    "layer_test_update_weight2.update_weight()\n",
    "print(layer_test_update_weight2.delta_weight_matrix_before)\n",
    "print(layer_test_update_weight2.weight_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Update Weight Without Momentum TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunakArtificialNeuralNetwork:\n",
    "    def __init__(self, loss='root_mean_squared', optimizer='sgd'):\n",
    "        assert loss == 'root_mean_squared', 'loss function not supported'\n",
    "        assert optimizer == 'sgd', 'optimizer not supported'\n",
    "        self.layers = []\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    def feed_forward(self, X_instance):\n",
    "        # Calculate output with the first hidden layer\n",
    "        output_list = self.layers[0].calculate_output(X_instance)\n",
    "        # Calculate output with the second until the last layer\n",
    "        for layer in self.layers[1:]:\n",
    "            next_output_list = layer.calculate_output(output_list)\n",
    "            output_list = next_output_list\n",
    "        return output_list.copy()\n",
    "            \n",
    "    def backpropagation(self, y_instance):\n",
    "        # Calculate local gradient for output layer\n",
    "        next_local_gradient_list = self.layers[-1].calculate_local_gradient_output_layer([y_instance])\n",
    "        next_layer_weight_matrix = self.layers[-1].weight_matrix\n",
    "\n",
    "        # Calculate local gradient for hidden layer(s)\n",
    "        for layer_idx, layer in enumerate(reversed(self.layers[0:-1])):\n",
    "            next_local_gradient_list = layer.calculate_local_gradient_hidden_layer(next_local_gradient_list, next_layer_weight_matrix)\n",
    "            next_layer_weight_matrix = layer.weight_matrix\n",
    "            \n",
    "    def calculate_delta_weight(self, X_instance, lr, momentum):\n",
    "        # Update delta weight for first hidden layer\n",
    "        self.layers[0].update_delta_weight(lr, X_instance, momentum)\n",
    "        \n",
    "        # Update delta weight for other layers\n",
    "        for layer_idx, layer in enumerate(self.layers[1:]):\n",
    "            layer.update_delta_weight(lr, self.layers[layer_idx].output_list, momentum)\n",
    "    \n",
    "    def fit(self, X, y, epochs, lr, momentum=None, batch_size=None, val_data=None, val_size=0):\n",
    "        assert X.shape[1] == self.layers[0].input_dim, 'Input dimension must be same with the column'\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        if batch_size == None:\n",
    "            batch_size = len(X)\n",
    "            \n",
    "        if val_data is None:\n",
    "            val_size = 0.1\n",
    "            X, X_val, y, y_val = train_test_split(X, y, test_size=val_size)\n",
    "        else:\n",
    "            X_val = val_data[0]\n",
    "            y_val = val_data[1]\n",
    "        \n",
    "        if val_data is not None and val_size != 0:\n",
    "            print('Validation data will be used instead of val_size.')\n",
    "            \n",
    "        for epoch in range(epochs):\n",
    "            print('epoch', epoch)\n",
    "            # SGD Batch / Mini Batch\n",
    "            delta = len(X) // batch_size\n",
    "            for start in range(0, len(X), delta):\n",
    "                X_batch = X[start:start+delta]\n",
    "                y_batch = y[start:start+delta]\n",
    "                \n",
    "                for idx, X_instance in enumerate(X_batch):\n",
    "                    self.feed_forward(X_instance)\n",
    "                    self.backpropagation(y_batch[idx][0])\n",
    "                    self.calculate_delta_weight(X_instance, lr, momentum)\n",
    "\n",
    "                for layer in self.layers:\n",
    "                    layer.update_weight()\n",
    "                    \n",
    "            pred = self.predict(X)\n",
    "            pred_val = self.predict(X_val)\n",
    "            \n",
    "            print('acc:', self.calculate_accuracy(y, pred))\n",
    "            print('val_acc:', self.calculate_accuracy(y_val, pred_val))\n",
    "            \n",
    "            # Loss\n",
    "            print('loss:', mean_squared_error(y, pred))\n",
    "            print('val_loss:', mean_squared_error(y_val, pred_val))\n",
    "            print()\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        predictions = []\n",
    "        for idx, X_instance in enumerate(X):\n",
    "            X_pred = self.feed_forward(X_instance)\n",
    "            predictions.append([np.mean(X_pred.copy())])\n",
    "        return predictions\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for idx, X_instance in enumerate(X):\n",
    "            X_pred_proba = self.feed_forward(X_instance)\n",
    "            X_pred = min(self.classes_, key=lambda pred_class:abs(pred_class - np.mean(X_pred_proba)))\n",
    "            predictions.append([X_pred.copy()])\n",
    "        return predictions\n",
    "    \n",
    "    def calculate_accuracy(self, y_true, y_pred):\n",
    "        if len(confusion_matrix(y_true, y_pred).ravel()) > 1:\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        else:\n",
    "            tp = confusion_matrix(y_true, y_pred).ravel()[0]\n",
    "            fp = 0\n",
    "            fn = 0\n",
    "            tn = 0\n",
    "        return (tp + tn) / (tp + tn + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LunakArtificialNeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LunakDense(2, 'sigmoid', 2, 'uniform', True))\n",
    "model.add(LunakDense(1, 'sigmoid', 2, 'uniform', True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.2  0.1  0.1]\n",
      " [-0.1  0.3  0.1]]\n",
      "[[0.2 0.3 0.2]]\n"
     ]
    }
   ],
   "source": [
    "model.layers[0].weight_matrix = np.array([[-0.2, 0.1, 0.1], [-0.1, 0.3, 0.1]])\n",
    "model.layers[1].weight_matrix = np.array([[0.2, 0.3, 0.2]])\n",
    "print(model.layers[0].weight_matrix)\n",
    "\n",
    "print(model.layers[1].weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([\n",
    "    [0.1, 0.9]\n",
    "])\n",
    "y_train = np.array([\n",
    "    0.9\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-495-1b8a480b2d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-490-afbc476e74c8>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, epochs, lr, momentum, batch_size)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_instance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_delta_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, 1, 0.25, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.19991775  0.10074028  0.10082253]\n",
      " [-0.09987967  0.30108299  0.10120332]]\n",
      "[0.00329012 0.00481328]\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weight_matrix)\n",
    "print(model.layers[0].local_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20898739 0.30976024 0.21656973]]\n",
      "[0.06627891]\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[1].weight_matrix)\n",
    "print(model.layers[1].local_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 4, 5, 9]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([1, 2, 4, 4, 5, 9, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agus Gunawan, Holy Lovenia, Felix Limanta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = loadarff('dataset/weather.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(raw_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'sunny'</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>b'FALSE'</td>\n",
       "      <td>b'no'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'sunny'</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>b'TRUE'</td>\n",
       "      <td>b'no'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'overcast'</td>\n",
       "      <td>83.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>b'FALSE'</td>\n",
       "      <td>b'yes'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'rainy'</td>\n",
       "      <td>70.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>b'FALSE'</td>\n",
       "      <td>b'yes'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'rainy'</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>b'FALSE'</td>\n",
       "      <td>b'yes'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       outlook  temperature  humidity     windy    play\n",
       "0     b'sunny'         85.0      85.0  b'FALSE'   b'no'\n",
       "1     b'sunny'         80.0      90.0   b'TRUE'   b'no'\n",
       "2  b'overcast'         83.0      86.0  b'FALSE'  b'yes'\n",
       "3     b'rainy'         70.0      96.0  b'FALSE'  b'yes'\n",
       "4     b'rainy'         68.0      80.0  b'FALSE'  b'yes'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary_vector(data):\n",
    "    return pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, column in enumerate(['outlook', 'windy', 'play']):\n",
    "    data[column] = data[column].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overcast</th>\n",
       "      <th>rainy</th>\n",
       "      <th>sunny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overcast  rainy  sunny\n",
       "0         0      0      1\n",
       "1         0      0      1\n",
       "2         1      0      0\n",
       "3         0      1      0\n",
       "4         0      1      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv_outlook = convert_to_binary_vector(data['outlook'])\n",
    "bv_outlook.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FALSE</th>\n",
       "      <th>TRUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FALSE  TRUE\n",
       "0      1     0\n",
       "1      0     1\n",
       "2      1     0\n",
       "3      1     0\n",
       "4      1     0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv_windy = convert_to_binary_vector(data['windy'])\n",
    "bv_windy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_data = data.drop('outlook', 1).drop('windy', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_data['play'] = preproc_data['play'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overcast</th>\n",
       "      <th>rainy</th>\n",
       "      <th>sunny</th>\n",
       "      <th>FALSE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overcast  rainy  sunny  FALSE  TRUE  temperature  humidity play\n",
       "0         0      0      1      1     0         85.0      85.0   no\n",
       "1         0      0      1      0     1         80.0      90.0   no\n",
       "2         1      0      0      1     0         83.0      86.0  yes\n",
       "3         0      1      0      1     0         70.0      96.0  yes\n",
       "4         0      1      0      1     0         68.0      80.0  yes"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data = pd.concat([bv_outlook, bv_windy, preproc_data], axis=1)\n",
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   play\n",
       "0     0\n",
       "1     0\n",
       "2     1\n",
       "3     1\n",
       "4     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame({'play': preprocessed_data['play'].cat.codes})\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessed_data.drop('play', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X.columns:\n",
    "    X[column] = X[column].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overcast</th>\n",
       "      <th>rainy</th>\n",
       "      <th>sunny</th>\n",
       "      <th>FALSE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overcast  rainy  sunny  FALSE  TRUE  temperature  humidity\n",
       "0       0.0    0.0    1.0    1.0   0.0         85.0      85.0\n",
       "1       0.0    0.0    1.0    0.0   1.0         80.0      90.0\n",
       "2       1.0    0.0    0.0    1.0   0.0         83.0      86.0\n",
       "3       0.0    1.0    0.0    1.0   0.0         70.0      96.0\n",
       "4       0.0    1.0    0.0    1.0   0.0         68.0      80.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y_new = [instance_y[0] for instance_y in np.array(y)]\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  1.,  0., 85., 85.],\n",
       "       [ 0.,  0.,  1.,  0.,  1., 80., 90.],\n",
       "       [ 1.,  0.,  0.,  1.,  0., 83., 86.],\n",
       "       [ 0.,  1.,  0.,  1.,  0., 70., 96.],\n",
       "       [ 0.,  1.,  0.,  1.,  0., 68., 80.],\n",
       "       [ 0.,  1.,  0.,  0.,  1., 65., 70.],\n",
       "       [ 1.,  0.,  0.,  0.,  1., 64., 65.],\n",
       "       [ 0.,  0.,  1.,  1.,  0., 72., 95.],\n",
       "       [ 0.,  0.,  1.,  1.,  0., 69., 70.],\n",
       "       [ 0.,  1.,  0.,  1.,  0., 75., 80.],\n",
       "       [ 0.,  0.,  1.,  0.,  1., 75., 70.],\n",
       "       [ 1.,  0.,  0.,  0.,  1., 72., 90.],\n",
       "       [ 1.,  0.,  0.,  1.,  0., 81., 75.],\n",
       "       [ 0.,  1.,  0.,  0.,  1., 71., 91.]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LunakANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunak_ann = LunakArtificialNeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02780068  0.03707323 -0.02932808  0.04186109 -0.00115888  0.01117439\n",
      "   0.02659079]\n",
      " [ 0.0018418  -0.02031995 -0.03122788 -0.04192587  0.02384403 -0.00586908\n",
      "  -0.03416901]]\n",
      "[[-0.02780068  0.03707323]]\n"
     ]
    }
   ],
   "source": [
    "lunak_ann.add(LunakDense(2, 'sigmoid', 7, 'uniform', False, seed=5))\n",
    "lunak_ann.add(LunakDense(1, 'sigmoid', 2, 'uniform', False, seed=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]] [[ 0.  1.  0.  1.  0. 75. 80.]\n",
      " [ 0.  1.  0.  1.  0. 70. 96.]]\n",
      "epoch 0\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 1\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 2\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 3\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 4\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 5\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 6\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 7\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 8\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 9\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 10\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 11\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 12\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 13\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 14\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 15\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 16\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 17\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 18\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 19\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 20\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 21\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 22\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 23\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 24\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 25\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 26\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 27\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 28\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 29\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 30\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 31\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 32\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 33\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 34\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 35\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 36\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 37\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 38\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 39\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 40\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 41\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 42\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 43\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 44\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 45\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 46\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 47\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 48\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n",
      "epoch 49\n",
      "acc: 0.5833333333333334\n",
      "val_acc: 1.0\n",
      "loss: 0.4166666666666667\n",
      "val_loss: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lunak_ann.fit(X, y, epochs=50, momentum=0.001, lr=0.001, batch_size=10, val_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix([0, 0, 0], [1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = lunak_ann.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1]]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.initializers import RandomUniform\n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_ann = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = RandomUniform(minval=-0.05, maxval=0.05, seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_ann.add(Dense(2, activation='sigmoid', input_dim=7, use_bias=False, kernel_initializer=initializer))\n",
    "keras_ann.add(Dense(1, activation='sigmoid', use_bias=False, kernel_initializer=initializer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ = keras.optimizers.SGD(momentum=0.001, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_ann.compile(loss='mean_squared_error', optimizer=optimizer_, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2495 - acc: 0.6429\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 128us/step - loss: 0.2495 - acc: 0.6429\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 135us/step - loss: 0.2495 - acc: 0.6429\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 131us/step - loss: 0.2495 - acc: 0.6429\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 125us/step - loss: 0.2495 - acc: 0.6429\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 113us/step - loss: 0.2494 - acc: 0.6429\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 109us/step - loss: 0.2494 - acc: 0.6429\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 108us/step - loss: 0.2494 - acc: 0.6429\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 119us/step - loss: 0.2494 - acc: 0.6429\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 108us/step - loss: 0.2494 - acc: 0.6429\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 156us/step - loss: 0.2494 - acc: 0.6429\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 248us/step - loss: 0.2494 - acc: 0.6429\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 150us/step - loss: 0.2494 - acc: 0.6429\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 152us/step - loss: 0.2494 - acc: 0.6429\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 184us/step - loss: 0.2494 - acc: 0.6429\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 205us/step - loss: 0.2494 - acc: 0.6429\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 142us/step - loss: 0.2493 - acc: 0.6429\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 131us/step - loss: 0.2493 - acc: 0.6429\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 216us/step - loss: 0.2493 - acc: 0.6429\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 206us/step - loss: 0.2493 - acc: 0.6429\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 249us/step - loss: 0.2493 - acc: 0.6429\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 183us/step - loss: 0.2493 - acc: 0.6429\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 139us/step - loss: 0.2493 - acc: 0.6429\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 397us/step - loss: 0.2493 - acc: 0.6429\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 197us/step - loss: 0.2493 - acc: 0.6429\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 143us/step - loss: 0.2493 - acc: 0.6429\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 244us/step - loss: 0.2493 - acc: 0.6429\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 183us/step - loss: 0.2493 - acc: 0.6429\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 172us/step - loss: 0.2492 - acc: 0.6429\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 165us/step - loss: 0.2492 - acc: 0.6429\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 164us/step - loss: 0.2492 - acc: 0.6429\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 132us/step - loss: 0.2492 - acc: 0.6429\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 695us/step - loss: 0.2492 - acc: 0.6429\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 178us/step - loss: 0.2492 - acc: 0.6429\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 144us/step - loss: 0.2492 - acc: 0.6429\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 159us/step - loss: 0.2492 - acc: 0.6429\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 181us/step - loss: 0.2492 - acc: 0.6429\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 187us/step - loss: 0.2492 - acc: 0.6429\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 166us/step - loss: 0.2491 - acc: 0.6429\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 206us/step - loss: 0.2491 - acc: 0.6429\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 177us/step - loss: 0.2491 - acc: 0.6429\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 135us/step - loss: 0.2491 - acc: 0.6429\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 332us/step - loss: 0.2491 - acc: 0.6429\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 199us/step - loss: 0.2491 - acc: 0.6429\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 174us/step - loss: 0.2491 - acc: 0.6429\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 135us/step - loss: 0.2491 - acc: 0.6429\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 181us/step - loss: 0.2490 - acc: 0.6429\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 124us/step - loss: 0.2490 - acc: 0.6429\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 731us/step - loss: 0.2490 - acc: 0.6429\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 241us/step - loss: 0.2490 - acc: 0.6429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f901044efd0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_ann.fit(X, y, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50374407],\n",
       "       [0.5038381 ],\n",
       "       [0.5038099 ],\n",
       "       [0.5039423 ],\n",
       "       [0.50372106],\n",
       "       [0.50357056],\n",
       "       [0.50346035],\n",
       "       [0.5038726 ],\n",
       "       [0.50347817],\n",
       "       [0.5037249 ],\n",
       "       [0.5035003 ],\n",
       "       [0.503881  ],\n",
       "       [0.50362927],\n",
       "       [0.50390553]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_ann.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
