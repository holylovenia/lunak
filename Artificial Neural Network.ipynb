{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Felix Limanta (13515065), Holy Lovenia (13515113), Agus Gunawan (13515143)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "An artificial neural network (ANN) is made of interconnected layers of nodes, emulating the structures and functions of neurons in human brain.\n",
    "\n",
    "Normally, connections between the nodes (neurons) are called edges. These edges are associated with weights, which adjusts themselves during the learning process.\n",
    "\n",
    "![Artificial neural network](img/artificial_neural_network_1-791x388.jpg)\n",
    "\n",
    "Nodes are typically grouped into specific layers. Different layers perform different transformations on their inputs. The first layer is regarded as input layer; the last is output layer. The output layer represents the final outputs of the network their corresponding predicted classes. Between the two layers, hidden layers may be present to process and transform the inputs by applying an activation function, then produce results according to the needs of output layer.\n",
    "\n",
    "The disconnected nodes in the network are called as bias nodes, which are useful to shift the activation function into a desired direction. Below is an example of network with the presence of bias nodes.\n",
    "\n",
    "![Network with bias](img/mlpdiagram.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing an Artificial Neural Network\n",
    "\n",
    "We introduce Lunak, a simple feed-forward neural network implementation in Python. The entire source code for Lunak is contained within this report and shall be shown in the following subsections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random, randint\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, tnrange\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the `LunakDense` class to represent our hidden layer and output layer. The parameters for this class are as follows.\n",
    "\n",
    "1. `units`: `int`, the number of nodes in the layer\n",
    "2. `activation`: `'sigmoid'`, activation function\n",
    "3. `input_dim`: `int`, dimension of the input (e.g. 2D, 3D, ...)\n",
    "4. `init`: `'uniform', 'random'`, type of distribution for the initial weight matrix\n",
    "5. `use_bias`: `boolean`, whether there will be bias node present or not (default=`False`)\n",
    "6. `seed`: `int`, the number of random seed (default=`None`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layer transforms input $p_j(t)$ to neuron $j$ from the outputs $o_i(t)$ of predecessor neurons and bias $w_{0j}$ according to the following propagation function.\n",
    "\n",
    "$$p_j(t) = \\sum_{i} o_i(t) w_{ij} + w_{0j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunakDense:\n",
    "    def __init__(self, units, activation,\n",
    "                 input_dim, init, use_bias=False, seed=None):\n",
    "        self.units = units\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        if activation == 'sigmoid':\n",
    "            self.activation_function = self.sigmoid\n",
    "        else:\n",
    "            print('Activation function not supported')\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        if init == 'uniform':\n",
    "            self.weight_matrix = np.random.uniform(-0.05, 0.05,\n",
    "                                                   size=(self.units, input_dim)) \n",
    "        elif init == 'random':\n",
    "            self.weight_matrix = np.random.random(size=(self.units, input_dim))\n",
    "        else:\n",
    "            print('Init function not supported')\n",
    "        \n",
    "        self.delta_weight_matrix_before = np.zeros((self.units, input_dim))\n",
    "        self.delta_weight_matrix = np.zeros((self.units, input_dim))\n",
    "        \n",
    "        self.use_bias = use_bias\n",
    "        if self.use_bias:\n",
    "            bias = np.zeros((units, 1))\n",
    "            self.weight_matrix = np.hstack((self.weight_matrix, bias))\n",
    "            self.delta_weight_matrix_before = np.hstack(\n",
    "                (self.delta_weight_matrix_before, np.zeros((units, 1))))\n",
    "            self.delta_weight_matrix = np.hstack(\n",
    "                (self.delta_weight_matrix, np.zeros((units, 1))))\n",
    "            \n",
    "    def init_delta_weight_zero(self):\n",
    "        for idx_unit, unit in enumerate(self.delta_weight_matrix):\n",
    "            for idx_source, source in enumerate(unit):\n",
    "                self.delta_weight_matrix[idx_unit] = 0\n",
    "                self.delta_weight_matrix_before[idx_unit] = 0\n",
    "                \n",
    "    def calculate_sigma(self, input_list):\n",
    "        if self.use_bias:\n",
    "            input_list = np.append(input_list, 1)\n",
    "        \n",
    "        result_list = np.array([])\n",
    "        for weight_neuron in self.weight_matrix:\n",
    "            result_list = np.append(result_list, np.dot(weight_neuron, input_list))\n",
    "        return np.array(result_list)\n",
    "    \n",
    "    def calculate_output(self, input_list):\n",
    "        output_list = np.array([])\n",
    "        for sigma_neuron in self.calculate_sigma(input_list):\n",
    "            output_list = np.append(output_list,\n",
    "                                    self.activation_function(sigma_neuron))\n",
    "        self.output_list = output_list\n",
    "        return output_list.copy()\n",
    "    \n",
    "    def calculate_local_gradient_output_layer(self, target_list):\n",
    "        \"\"\"\n",
    "        Use this if the layer is output layer\n",
    "        \"\"\"\n",
    "        result_list = np.array([])\n",
    "        for index, output in enumerate(self.output_list):\n",
    "            local_gradient = output * (1 - output) * (target_list[index] - output)\n",
    "            result_list = np.append(result_list, local_gradient)  \n",
    "        self.local_gradient = result_list\n",
    "        return result_list.copy()\n",
    "    \n",
    "    def calculate_local_gradient_hidden_layer(self,\n",
    "                                              local_gradient_output_list,\n",
    "                                              output_layer_weight_matrix):\n",
    "        \"\"\"\n",
    "        Use this if the layer is hidden layer\n",
    "        \"\"\"\n",
    "        result_list = np.array([])\n",
    "        for index, output in enumerate(self.output_list):\n",
    "            sigma_local_gradient_output = 0\n",
    "            for unit_number, local_gradient in enumerate(local_gradient_output_list):\n",
    "                sigma_local_gradient_output += \\\n",
    "                    output_layer_weight_matrix[unit_number][index] * local_gradient\n",
    "            error_hidden = output * (1 - output) * sigma_local_gradient_output\n",
    "            result_list = np.append(result_list, error_hidden)\n",
    "        self.local_gradient = result_list\n",
    "        return result_list.copy()\n",
    "    \n",
    "    def update_delta_weight(self, lr, input_list, momentum=None):\n",
    "        \"\"\"\n",
    "        Function to update delta weight\n",
    "        \"\"\"\n",
    "        if self.use_bias:\n",
    "            input_list = np.append(input_list, 1)\n",
    "        if momentum == None:\n",
    "            for j, unit in enumerate(self.weight_matrix): #j  \n",
    "                for i, source in enumerate(unit): #i\n",
    "                    delta_weight = self.delta_weight_matrix[j][i] \\\n",
    "                        + lr * self.local_gradient[j] * input_list[i]\n",
    "                    self.delta_weight_matrix[j][i] = delta_weight.copy()\n",
    "        else:\n",
    "            for j, unit in enumerate(self.weight_matrix): #j  \n",
    "                for i, source in enumerate(unit): #i\n",
    "                    delta_weight = self.delta_weight_matrix[j][i] \\\n",
    "                        + lr * self.local_gradient[j] * input_list[i] \\\n",
    "                        + momentum * self.delta_weight_matrix_before[j][i]\n",
    "                    \n",
    "                    # Update Delta Weight\n",
    "                    self.delta_weight_matrix_before[j][i] = delta_weight.copy()\n",
    "            \n",
    "            # Copy Last Update of Weight Matrix Before (Equal to Last Weight Matrix)\n",
    "            for j, unit in enumerate(self.delta_weight_matrix_before):\n",
    "                for i, source in enumerate(unit):\n",
    "                    self.delta_weight_matrix[j][i] = \\\n",
    "                        self.delta_weight_matrix_before[j][i].copy()\n",
    "            \n",
    "    def update_weight(self):\n",
    "        \"\"\"\n",
    "        Function to update weight\n",
    "        \"\"\"\n",
    "        for j, unit in enumerate(self.delta_weight_matrix_before):\n",
    "            for i, source in enumerate(unit):\n",
    "                self.weight_matrix[j][i] += self.delta_weight_matrix[j][i]\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ANN model is implemented using stochastic gradient descent (SGD) as the learning rule. SGD is known as a strategy for searching through a large or infinite hypothesis space.\n",
    "\n",
    "Training an ANN typically entails two steps: feed-forward and backpropagation.\n",
    "\n",
    "![ANN steps](img/Back-propagation-multilayer-ANN-with-one-hidden-layer.png)\n",
    "\n",
    "- **Feed-forward** predicts output classes from the given inputs using the weights the network currently posseses.\n",
    "- **Backpropagation** calculates the error in each neuron (based on the predicted class and its ground truth) and updates the weights accordingly.\n",
    "\n",
    "The algorithm used for the feed-forward and backpropagation is based on the algorithm in the book [Machine Learning (Mitchell, 1997, p. 98)](https://www.cs.ubbcluj.ro/~gabis/ml/ml-books/McGrawHill%20-%20Machine%20Learning%20-Tom%20Mitchell.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the `LunakArtificialNeuralNetwork` class to represent our neural network model. The class possesses two notable methods:\n",
    "- `fit(·)`: Trains a model with a given dataset, and\n",
    "- `predict(·)`: Receives input data and produces predictions according to the trained model.\n",
    "\n",
    "The following parameters are used for `fit(·)`.\n",
    "1. `X`: `data`, training data\n",
    "2. `y`: `data`, labels for training data\n",
    "3. `epochs`: `int`, the number of epochs that will be run\n",
    "4. `lr`: `float`, learning rate\n",
    "5. `momentum`: `float`, momentum (used to prevent local minima)\n",
    "6. `batch_size`: `int`, incremental when 1 (default=`len(X)`)\n",
    "7. `val_data`: `(X_val, y_val)`, for validation purposes (default=`None`, will use `val_size`=0.1)\n",
    "8. `val_size`: `float`, used to split X and y to get validation data (default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunakArtificialNeuralNetwork:\n",
    "    def __init__(self, loss='root_mean_squared', optimizer='sgd'):\n",
    "        assert loss == 'root_mean_squared', 'loss function not supported'\n",
    "        assert optimizer == 'sgd', 'optimizer not supported'\n",
    "        self.layers = []\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    def feed_forward(self, X_instance):\n",
    "        # Calculate output with the first hidden layer\n",
    "        output_list = self.layers[0].calculate_output(X_instance)\n",
    "        # Calculate output with the second until the last layer\n",
    "        for layer in self.layers[1:]:\n",
    "            next_output_list = layer.calculate_output(output_list)\n",
    "            output_list = next_output_list\n",
    "        return output_list.copy()\n",
    "            \n",
    "    def backpropagation(self, y_instance):\n",
    "        # Calculate local gradient for output layer\n",
    "        next_local_gradient_list = \\\n",
    "            self.layers[-1].calculate_local_gradient_output_layer([y_instance])\n",
    "        next_layer_weight_matrix = self.layers[-1].weight_matrix\n",
    "\n",
    "        # Calculate local gradient for hidden layer(s)\n",
    "        for layer_idx, layer in enumerate(reversed(self.layers[0:-1])):\n",
    "            next_local_gradient_list = \\\n",
    "                layer.calculate_local_gradient_hidden_layer(next_local_gradient_list,\n",
    "                                                            next_layer_weight_matrix)\n",
    "            next_layer_weight_matrix = layer.weight_matrix\n",
    "            \n",
    "    def calculate_delta_weight(self, X_instance, lr, momentum):\n",
    "        # Update delta weight for first hidden layer\n",
    "        self.layers[0].update_delta_weight(lr, X_instance, momentum)\n",
    "        \n",
    "        # Update delta weight for other layers\n",
    "        for layer_idx, layer in enumerate(self.layers[1:]):\n",
    "            layer.update_delta_weight(lr, self.layers[layer_idx].output_list,\n",
    "                                      momentum)\n",
    "    \n",
    "    def fit(self, X, y, epochs, lr, momentum=None,\n",
    "            batch_size=None, val_data=None, val_size=0):\n",
    "        assert X.shape[1] == self.layers[0].input_dim, \\\n",
    "            'Input dimension must be same with the column'\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        if batch_size == None:\n",
    "            batch_size = len(X)\n",
    "            \n",
    "        if val_data is None:\n",
    "            val_size = 0.1\n",
    "            X, X_val, y, y_val = train_test_split(X, y, test_size=val_size)\n",
    "        else:\n",
    "            X_val = val_data[0]\n",
    "            y_val = val_data[1]\n",
    "            \n",
    "        print('Train on {} samples, validate on {} samples'.format(len(X),\n",
    "                                                                   len(X_val)))\n",
    "        \n",
    "        if val_data is not None and val_size != 0:\n",
    "            print('Validation data will be used instead of val_size.')\n",
    "            \n",
    "        for epoch in range(epochs):\n",
    "            delta = batch_size\n",
    "            \n",
    "            with tnrange(0, len(X), delta,\n",
    "                         desc='Epoch {}'.format(epoch + 1)) as pbar:\n",
    "                for start in pbar:\n",
    "                    X_batch = X[start:start+delta]\n",
    "                    y_batch = y[start:start+delta]\n",
    "\n",
    "                    for idx, X_instance in enumerate(X_batch):\n",
    "                        self.feed_forward(X_instance)\n",
    "                        self.backpropagation(y_batch[idx][0])\n",
    "                        self.calculate_delta_weight(X_instance, lr, momentum)\n",
    "\n",
    "                    for layer in self.layers:\n",
    "                        layer.update_weight()\n",
    "                        layer.init_delta_weight_zero()\n",
    "\n",
    "                    pred = self.predict(X)\n",
    "                    pred_val = self.predict(X_val)\n",
    "                    \n",
    "                    pred_proba = self.predict_proba(X)\n",
    "                    pred_proba_val = self.predict_proba(X_val)\n",
    "\n",
    "                    acc = self.calculate_accuracy(y, pred)\n",
    "                    val_acc = self.calculate_accuracy(y_val, pred_val)\n",
    "                    loss = mean_squared_error(y, pred_proba)\n",
    "                    val_loss = mean_squared_error(y_val, pred_proba_val)\n",
    "\n",
    "                    postfix = {\n",
    "                        'loss': loss,\n",
    "                        'acc': acc,\n",
    "                        'val_loss': val_loss,\n",
    "                        'val_acc': val_acc\n",
    "                    }\n",
    "                    pbar.set_postfix(postfix, refresh=True)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        predictions = []\n",
    "        for idx, X_instance in enumerate(X):\n",
    "            X_pred = self.feed_forward(X_instance)\n",
    "            predictions.append([np.mean(X_pred.copy())])\n",
    "        return predictions\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for idx, X_instance in enumerate(X):\n",
    "            X_pred_proba = self.feed_forward(X_instance)\n",
    "            X_pred = min(self.classes_,\n",
    "                         key=lambda pred_class:abs(pred_class - np.mean(X_pred_proba)))\n",
    "            predictions.append([X_pred])\n",
    "        return predictions\n",
    "    \n",
    "    def calculate_accuracy(self, y_true, y_pred):\n",
    "        if len(confusion_matrix(y_true, y_pred).ravel()) > 1:\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        else:\n",
    "            tp = confusion_matrix(y_true, y_pred).ravel()[0]\n",
    "            fp = 0\n",
    "            fn = 0\n",
    "            tn = 0\n",
    "        return (tp + tn) / (tp + tn + fp + fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing our implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test whether Lunak works correctly, we train both our model and a Keras ANN model as baseline, then compare their results and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "import pandas as pd\n",
    "from IPython.utils import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is the Play Tennis dataset, obtained from the [Weka Data Sets](http://storm.cis.fordham.edu/~gweiss/data-mining/weka-data/weather.arff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'sunny'</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>b'FALSE'</td>\n",
       "      <td>b'no'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'sunny'</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>b'TRUE'</td>\n",
       "      <td>b'no'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'overcast'</td>\n",
       "      <td>83.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>b'FALSE'</td>\n",
       "      <td>b'yes'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'rainy'</td>\n",
       "      <td>70.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>b'FALSE'</td>\n",
       "      <td>b'yes'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'rainy'</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>b'FALSE'</td>\n",
       "      <td>b'yes'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       outlook  temperature  humidity     windy    play\n",
       "0     b'sunny'         85.0      85.0  b'FALSE'   b'no'\n",
       "1     b'sunny'         80.0      90.0   b'TRUE'   b'no'\n",
       "2  b'overcast'         83.0      86.0  b'FALSE'  b'yes'\n",
       "3     b'rainy'         70.0      96.0  b'FALSE'  b'yes'\n",
       "4     b'rainy'         68.0      80.0  b'FALSE'  b'yes'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = loadarff('dataset/weather.arff')\n",
    "data = pd.DataFrame(raw_data[0])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train our model, we must first preprocess our data, as the data types of our chosen dataset cannot be fed to our ANN out-of-the-box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary_vector(data):\n",
    "    return pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we decode strings and boolean data in the dataset as UTF-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, column in enumerate(['outlook', 'windy', 'play']):\n",
    "    data[column] = data[column].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, string categoricals in the data (i.e., `outlook` and `windy`) are converted to one-hot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overcast</th>\n",
       "      <th>rainy</th>\n",
       "      <th>sunny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overcast  rainy  sunny\n",
       "0         0      0      1\n",
       "1         0      0      1\n",
       "2         1      0      0\n",
       "3         0      1      0\n",
       "4         0      1      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv_outlook = convert_to_binary_vector(data['outlook'])\n",
    "bv_outlook.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FALSE</th>\n",
       "      <th>TRUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FALSE  TRUE\n",
       "0      1     0\n",
       "1      0     1\n",
       "2      1     0\n",
       "3      1     0\n",
       "4      1     0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv_windy = convert_to_binary_vector(data['windy'])\n",
    "bv_windy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the categorical `outlook` and `windy` data and concatenate our one-hot vectors to the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_data = data.drop('outlook', 1).drop('windy', 1)\n",
    "preprocessed_data = pd.concat([bv_outlook, bv_windy, preproc_data], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target column, `play`, is processed as categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overcast</th>\n",
       "      <th>rainy</th>\n",
       "      <th>sunny</th>\n",
       "      <th>FALSE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overcast  rainy  sunny  FALSE  TRUE  temperature  humidity play\n",
       "0         0      0      1      1     0         85.0      85.0   no\n",
       "1         0      0      1      0     1         80.0      90.0   no\n",
       "2         1      0      0      1     0         83.0      86.0  yes\n",
       "3         0      1      0      1     0         70.0      96.0  yes\n",
       "4         0      1      0      1     0         68.0      80.0  yes"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_data['play'] = preproc_data['play'].astype('category')\n",
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The, the `play` column is converted to binary 0/1 integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   play\n",
       "0     0\n",
       "1     0\n",
       "2     1\n",
       "3     1\n",
       "4     1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame({'play': preproc_data['play'].cat.codes})\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training, we delete our target column from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessed_data.drop('play', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then cast all data remaining in the dataset as floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X.columns:\n",
    "    X[column] = X[column].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize real number data (`temperature` and `humidity`) to $[0, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['temperature', 'humidity']:\n",
    "    X[column] = (X[column] - min(X[column])) / (max(X[column]) - min(X[column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overcast</th>\n",
       "      <th>rainy</th>\n",
       "      <th>sunny</th>\n",
       "      <th>FALSE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.483871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overcast  rainy  sunny  FALSE  TRUE  temperature  humidity\n",
       "0       0.0    0.0    1.0    1.0   0.0     1.000000  0.645161\n",
       "1       0.0    0.0    1.0    0.0   1.0     0.761905  0.806452\n",
       "2       1.0    0.0    0.0    1.0   0.0     0.904762  0.677419\n",
       "3       0.0    1.0    0.0    1.0   0.0     0.285714  1.000000\n",
       "4       0.0    1.0    0.0    1.0   0.0     0.190476  0.483871"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also cast our target labels to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both our dataset and our target labels are converted to `numpy` arrays for faster processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is our preprocessed data and their labels. We shall feed this preprocessed data into our ANN implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "        1.        , 0.64516129],\n",
       "       [0.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.76190476, 0.80645161],\n",
       "       [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.9047619 , 0.67741935],\n",
       "       [0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "        0.28571429, 1.        ],\n",
       "       [0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "        0.19047619, 0.48387097],\n",
       "       [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.04761905, 0.16129032],\n",
       "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "        0.38095238, 0.96774194],\n",
       "       [0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "        0.23809524, 0.16129032],\n",
       "       [0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "        0.52380952, 0.48387097],\n",
       "       [0.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.52380952, 0.16129032],\n",
       "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.38095238, 0.80645161],\n",
       "       [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.80952381, 0.32258065],\n",
       "       [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.33333333, 0.83870968]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold-out split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training and validation, we employ a 90-10 holdout validation scheme, i.e., 90% data is used for training, while the remaining 10% is used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_val, y, y_val = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training our models\n",
    "We shall now build, train, and test Lunak and Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lunak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall first initialize our Lunak ANN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunak_ann = LunakArtificialNeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On our model, we add a hidden layer with two units and an output layer with one unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunak_ann.add(LunakDense(2, 'sigmoid', 7, 'uniform', use_bias=True, seed=5))\n",
    "lunak_ann.add(LunakDense(1, 'sigmoid', 2, 'uniform', use_bias=True, seed=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train our Lunak model using the preprocessed data and labels from the previous section across 10 epochs.\n",
    "\n",
    "As the dataset is quite small, training should not take too much time. We use `jupyter`'s `%timeit` function to measure the average training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533 ms ± 62.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with io.capture_output() as captured:\n",
    "    lunak_ann.fit(X, y, epochs=10, momentum=0.001,\n",
    "                  lr=0.01, batch_size=4, val_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the original dataset using the trained models yield the following predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5986759362416141],\n",
       " [0.5977620134260081],\n",
       " [0.5978382872859325],\n",
       " [0.5976941219147527],\n",
       " [0.5979907498942453],\n",
       " [0.5983622001595633],\n",
       " [0.5985349949605846],\n",
       " [0.5986546575535244],\n",
       " [0.5984597055343299],\n",
       " [0.5983042184694954],\n",
       " [0.5983673455929349],\n",
       " [0.5984547249383486]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba = lunak_ann.predict_proba(X)\n",
    "pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilities are then converted to predicted classes as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lunak_ann.predict(X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.initializers import RandomUniform\n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall first initialize our Lunak ANN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_ann = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the weight matrix with a random uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = RandomUniform(minval=-0.05, maxval=0.05, seed=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similiarly with our Lunak model, we add a hidden layer with 2 units and an output layer with 1 unit to our Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_ann.add(Dense(2, activation='sigmoid',\n",
    "                    input_dim=7, use_bias=True, kernel_initializer=initializer))\n",
    "keras_ann.add(Dense(1, activation='sigmoid',\n",
    "                    use_bias=True, kernel_initializer=initializer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Stochastic Gradient Descent as our Keras model optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ = keras.optimizers.SGD(momentum=0.001, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_ann.compile(loss='mean_squared_error',\n",
    "                  optimizer=optimizer_, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train our Keras model using the preprocessed data and labels from the previous section. Similiarly, we use `%timeit` to measure average training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.4 ms ± 10.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with io.capture_output() as captured:\n",
    "    keras_ann.fit(X, y, epochs=10, batch_size=4, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the original dataset using the trained models yield the following predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5604244 ],\n",
       "       [0.56077284],\n",
       "       [0.5607391 ],\n",
       "       [0.5608534 ],\n",
       "       [0.56050277],\n",
       "       [0.5607991 ],\n",
       "       [0.5605264 ],\n",
       "       [0.5604657 ],\n",
       "       [0.56070906],\n",
       "       [0.5607866 ],\n",
       "       [0.560738  ],\n",
       "       [0.5607262 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob = keras_ann.predict(X)\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then convert the predicted probabilities to binary classes, with a threshold of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "pred = [1 if x > threshold else 0 for x in pred_prob]\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "## Accuracy\n",
    "\n",
    "Both our Lunak model and our Keras model produced the same predictions, i.e., all data are predicted as 1. This proves that our implementation works correctly for small datasets.\n",
    "\n",
    "For results predicted both by Lunak and by Keras, even predicting the original dataset yields low accuracy. This is due to the small dataset used for training and testing. For larger datasets, the accuracy should improve.\n",
    "\n",
    "## Performance \n",
    "\n",
    "Even though both our Lunak model and the baseline Keras model produces the same results, training the Keras model is an order of magnitude faster than training our Lunak model (~500ms vs. ~20ms). This is due to the following factors.\n",
    "\n",
    "- Lunak is a textbook implementation of machine learning algorithms; no performance tricks are used. Tensorflow (and, by extension, Keras) is very much optimized to eke out the smallest edge in performance.\n",
    "- Lunak is build purely on Python, even though libraries used here may be implemented in other languages. The core of Tensorflow is written in C++/CUDA.\n",
    "- Lunak uses `numpy` for numerical operations, while Tensorflow, uses Eigen (a high-performance C++/CUDA numerical library), in addition to Nvidia's cuDNN.\n",
    "- Lunak is single-threaded and runs purely in the CPU. Our Keras model uses Tensorflow-GPU, which utilizes both the CPU and the GPU for processing.\n",
    "\n",
    "Random weight initialization may impact performance, but running the training process several times produce roughly the same 6:1 execution time ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roles and Responsibilities\n",
    "\n",
    "| Name | SID | Role |\n",
    "|---|---|---|\n",
    "| Felix Limanta | 13515065 | Layer and model implementation, debugging, Keras exploration, writing report |\n",
    "| Holy Lovenia | 13515113 | Layer and model implementation, debugging, Keras exploration, writing report |\n",
    "| Felix Limanta | 13515143 | Layer and model implementation, debugging, Keras exploration, writing report |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
