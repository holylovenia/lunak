{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Felix Limanta (13515065), Holy Lovenia (13515113), Agus Gunawan (13515143)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial neural network (ANN) is made of interconnected layers of nodes, which is similar to the structures and functions of neurons in human brain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, connections between the nodes (neurons) are called as edges. These edges are associated with weights, which will adjust themselves during learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Artificial neural network](https://icdn5.digitaltrends.com/image/artificial_neural_network_1-791x388.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes are typically grouped into specific layers. Different layers perform different transformations on their inputs. The first layer is regarded as input layer, while the last is output layer. Output layer is used to represent the final outputs as their corresponding predicted classes. Between input and output layer, hidden layers may be present to process the inputs by applying an activation function and produce results according to the needs of output layer.\n",
    "\n",
    "The disconnected nodes in the network are called as bias nodes, which are useful to shift the activation function to the desired direction. Below is an example of network with the presence of bias nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Network with bias](http://documentation.statsoft.com/STATISTICAHelp/SANN/Images/mlpdiagram.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random, randint\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, tnrange\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we implement `LunakDense` class to represent the hidden layer and output layer, with parameters as listed below.\n",
    "\n",
    "1. `units`: `int`, the number of nodes in the layer\n",
    "\n",
    "2. `activation`: `'sigmoid'`, activation function\n",
    "\n",
    "3. `input_dim`: `int`, dimension of the input (e.g. 2D, 3D, ...)\n",
    "\n",
    "4. `init`: `'uniform', 'random'`, type of distribution for the initial weight matrix\n",
    "\n",
    "5. `use_bias`: `boolean`, whether there will be bias node present or not (default=`False`)\n",
    "\n",
    "6. `seed`: `int`, the number of random seed (default=`None`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propagation function**\n",
    "\n",
    "It computes input $p_j(t)$ to neuron $j$ from the outputs $o_i(t)$ of predecessor neurons and bias $w_{0j}$\n",
    "\n",
    "![Sigma](https://wikimedia.org/api/rest_v1/media/math/render/svg/53a6369d6948c2a582469ed48def95b151953e9d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunakDense:\n",
    "    def __init__(self, units, activation, input_dim, init, use_bias=False, seed=None):\n",
    "        self.units = units\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        if activation == 'sigmoid':\n",
    "            self.activation_function = self.sigmoid\n",
    "        else:\n",
    "            print('Activation function not supported')\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        if init == 'uniform':\n",
    "            self.weight_matrix = np.random.uniform(-0.05, 0.05, size=(self.units, input_dim)) \n",
    "        elif init == 'random':\n",
    "            self.weight_matrix = np.random.random(size=(self.units, input_dim))\n",
    "        else:\n",
    "            print('Init function not supported')\n",
    "        \n",
    "        self.delta_weight_matrix_before = np.zeros((self.units, input_dim))\n",
    "        self.delta_weight_matrix = np.zeros((self.units, input_dim))\n",
    "        \n",
    "        self.use_bias = use_bias\n",
    "        if self.use_bias:\n",
    "            bias = np.zeros((units, 1))\n",
    "            self.weight_matrix = np.hstack((self.weight_matrix, bias))\n",
    "            self.delta_weight_matrix_before = np.hstack((self.delta_weight_matrix_before, np.zeros((units, 1))))\n",
    "            self.delta_weight_matrix = np.hstack((self.delta_weight_matrix, np.zeros((units, 1))))\n",
    "            \n",
    "    def calculate_sigma(self, input_list):\n",
    "        if self.use_bias:\n",
    "            input_list = np.append(input_list, 1)\n",
    "        \n",
    "        result_list = np.array([])\n",
    "        for weight_neuron in self.weight_matrix:\n",
    "            result_list = np.append(result_list, np.dot(weight_neuron, input_list))\n",
    "        return np.array(result_list)\n",
    "    \n",
    "    def calculate_output(self, input_list):\n",
    "        output_list = np.array([])\n",
    "        for sigma_neuron in self.calculate_sigma(input_list):\n",
    "            output_list = np.append(output_list, self.activation_function(sigma_neuron))\n",
    "        self.output_list = output_list\n",
    "        return output_list.copy()\n",
    "    \n",
    "    def calculate_local_gradient_output_layer(self, target_list):\n",
    "        \"\"\"\n",
    "        Use this if the layer is output layer\n",
    "        \"\"\"\n",
    "        result_list = np.array([])\n",
    "        for index, output in enumerate(self.output_list):\n",
    "            local_gradient = output * (1 - output) * (target_list[index] - output)\n",
    "            result_list = np.append(result_list, local_gradient)  \n",
    "        self.local_gradient = result_list\n",
    "        return result_list.copy()\n",
    "    \n",
    "    def calculate_local_gradient_hidden_layer(self, local_gradient_output_list, output_layer_weight_matrix):\n",
    "        \"\"\"\n",
    "        Use this if the layer is hidden layer\n",
    "        \"\"\"\n",
    "        result_list = np.array([])\n",
    "        for index, output in enumerate(self.output_list):\n",
    "            sigma_local_gradient_output = 0\n",
    "            for unit_number, local_gradient in enumerate(local_gradient_output_list):\n",
    "                sigma_local_gradient_output += output_layer_weight_matrix[unit_number][index] * local_gradient\n",
    "            error_hidden = output * (1 - output) * sigma_local_gradient_output\n",
    "            result_list = np.append(result_list, error_hidden)\n",
    "        self.local_gradient = result_list\n",
    "        return result_list.copy()\n",
    "    \n",
    "    def update_delta_weight(self, lr, input_list, momentum=None):\n",
    "        \"\"\"\n",
    "        Function to update delta weight\n",
    "        \"\"\"\n",
    "        if self.use_bias:\n",
    "            input_list = np.append(input_list, 1)\n",
    "        if momentum == None:\n",
    "            for j, unit in enumerate(self.weight_matrix): #j  \n",
    "                for i, source in enumerate(unit): #i\n",
    "                    delta_weight = lr * self.local_gradient[j] * input_list[i]\n",
    "                    self.delta_weight_matrix[j][i] = delta_weight.copy()\n",
    "        else:\n",
    "            for j, unit in enumerate(self.weight_matrix): #j  \n",
    "                for i, source in enumerate(unit): #i\n",
    "                    delta_weight = lr * self.local_gradient[j] * input_list[i] + momentum * self.delta_weight_matrix_before[j][i]\n",
    "                    \n",
    "                    # Update Delta Weight\n",
    "                    self.delta_weight_matrix_before[j][i] = delta_weight.copy()\n",
    "            \n",
    "            # Copy Last Update of Weight Matrix Before (Equal to Last Weight Matrix)\n",
    "            for j, unit in enumerate(self.delta_weight_matrix_before):\n",
    "                for i, source in enumerate(unit):\n",
    "                    self.delta_weight_matrix[j][i] = self.delta_weight_matrix_before[j][i].copy()\n",
    "            \n",
    "    def update_weight(self):\n",
    "        \"\"\"\n",
    "        Function to update weight\n",
    "        \"\"\"\n",
    "        for j, unit in enumerate(self.delta_weight_matrix_before):\n",
    "            for i, source in enumerate(unit):\n",
    "                self.weight_matrix[j][i] += self.delta_weight_matrix[j][i]\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN model is implemented using stochastic gradient descent (SGD) as the learning rule. SGD is known as a strategy for searching through a large or infinite hypothesis space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN typically consists of two steps: feed-forward and backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ANN steps](https://www.researchgate.net/profile/Morteza_Esfandyari/publication/241741756/figure/fig2/AS:298577172680729@1448197753779/Back-propagation-multilayer-ANN-with-one-hidden-layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed-forward is used to predict the given inputs based on the weights the network currently has."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Feed-forward](https://d18rbf1v22mj88.cloudfront.net/wp-content/uploads/sites/3/2018/03/13094759/neural_networks_fully_connected_layers_gumgum1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation is used to calculate the error in each node and update the weights based on the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Backpropagation](https://raw.githubusercontent.com/mtoto/mtoto.github.io/master/data/2017-11-08-net/result.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm used for the feed-forward and backpropagation is based on [Machine Learning book by Tom Mitchell](https://www.cs.ubbcluj.ro/~gabis/ml/ml-books/McGrawHill%20-%20Machine%20Learning%20-Tom%20Mitchell.pdf) on page 98."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters used for training (`fit` method).\n",
    "\n",
    "1. `X`: `data`, training data\n",
    "\n",
    "2. `y`: `data`, labels for training data\n",
    "\n",
    "3. `epochs`: `int`, the number of epochs that will be run\n",
    "\n",
    "4. `lr`: `float`, learning rate\n",
    "\n",
    "5. `momentum`: `float`, momentum (used to prevent local minima)\n",
    "\n",
    "6. `batch_size`: `int`, incremental when 1 (default=`len(X)`)\n",
    "\n",
    "7. `val_data`: `(X_val, y_val)`, for validation purposes (default=`None`, will use `val_size`=0.1)\n",
    "\n",
    "8. `val_size`: `float`, used to split X and y to get validation data (default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunakArtificialNeuralNetwork:\n",
    "    def __init__(self, loss='root_mean_squared', optimizer='sgd'):\n",
    "        assert loss == 'root_mean_squared', 'loss function not supported'\n",
    "        assert optimizer == 'sgd', 'optimizer not supported'\n",
    "        self.layers = []\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    def feed_forward(self, X_instance):\n",
    "        # Calculate output with the first hidden layer\n",
    "        output_list = self.layers[0].calculate_output(X_instance)\n",
    "        # Calculate output with the second until the last layer\n",
    "        for layer in self.layers[1:]:\n",
    "            next_output_list = layer.calculate_output(output_list)\n",
    "            output_list = next_output_list\n",
    "        return output_list.copy()\n",
    "            \n",
    "    def backpropagation(self, y_instance):\n",
    "        # Calculate local gradient for output layer\n",
    "        next_local_gradient_list = self.layers[-1].calculate_local_gradient_output_layer([y_instance])\n",
    "        next_layer_weight_matrix = self.layers[-1].weight_matrix\n",
    "\n",
    "        # Calculate local gradient for hidden layer(s)\n",
    "        for layer_idx, layer in enumerate(reversed(self.layers[0:-1])):\n",
    "            next_local_gradient_list = layer.calculate_local_gradient_hidden_layer(next_local_gradient_list, next_layer_weight_matrix)\n",
    "            next_layer_weight_matrix = layer.weight_matrix\n",
    "            \n",
    "    def calculate_delta_weight(self, X_instance, lr, momentum):\n",
    "        # Update delta weight for first hidden layer\n",
    "        self.layers[0].update_delta_weight(lr, X_instance, momentum)\n",
    "        \n",
    "        # Update delta weight for other layers\n",
    "        for layer_idx, layer in enumerate(self.layers[1:]):\n",
    "            layer.update_delta_weight(lr, self.layers[layer_idx].output_list, momentum)\n",
    "    \n",
    "    def fit(self, X, y, epochs, lr, momentum=None, batch_size=None, val_data=None, val_size=0):\n",
    "        assert X.shape[1] == self.layers[0].input_dim, 'Input dimension must be same with the column'\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        if batch_size == None:\n",
    "            batch_size = len(X)\n",
    "            \n",
    "        if val_data is None:\n",
    "            val_size = 0.1\n",
    "            X, X_val, y, y_val = train_test_split(X, y, test_size=val_size)\n",
    "        else:\n",
    "            X_val = val_data[0]\n",
    "            y_val = val_data[1]\n",
    "            \n",
    "        print('Train on {} samples, validate on {} samples'.format(len(X), len(X_val)))\n",
    "        \n",
    "        if val_data is not None and val_size != 0:\n",
    "            print('Validation data will be used instead of val_size.')\n",
    "            \n",
    "        for epoch in range(epochs):\n",
    "            delta = batch_size\n",
    "            \n",
    "            with tnrange(0, len(X), delta, desc='Epoch {}'.format(epoch + 1)) as pbar:\n",
    "                for start in pbar:\n",
    "                    X_batch = X[start:start+delta]\n",
    "                    y_batch = y[start:start+delta]\n",
    "\n",
    "                    for idx, X_instance in enumerate(X_batch):\n",
    "                        self.feed_forward(X_instance)\n",
    "                        self.backpropagation(y_batch[idx][0])\n",
    "                        self.calculate_delta_weight(X_instance, lr, momentum)\n",
    "\n",
    "                    for layer in self.layers:\n",
    "                        layer.update_weight()\n",
    "\n",
    "                    pred = self.predict(X)\n",
    "                    pred_val = self.predict(X_val)\n",
    "                    \n",
    "                    pred_proba = self.predict_proba(X)\n",
    "                    pred_proba_val = self.predict_proba(X_val)\n",
    "\n",
    "                    acc = self.calculate_accuracy(y, pred)\n",
    "                    val_acc = self.calculate_accuracy(y_val, pred_val)\n",
    "                    loss = mean_squared_error(y, pred_proba)\n",
    "                    val_loss = mean_squared_error(y_val, pred_proba_val)\n",
    "\n",
    "                    postfix = {\n",
    "                        'loss': loss,\n",
    "                        'acc': acc,\n",
    "                        'val_loss': val_loss,\n",
    "                        'val_acc': val_acc\n",
    "                    }\n",
    "                    pbar.set_postfix(postfix, refresh=True)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        predictions = []\n",
    "        for idx, X_instance in enumerate(X):\n",
    "            X_pred = self.feed_forward(X_instance)\n",
    "            predictions.append([np.mean(X_pred.copy())])\n",
    "        return predictions\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for idx, X_instance in enumerate(X):\n",
    "            X_pred_proba = self.feed_forward(X_instance)\n",
    "            X_pred = min(self.classes_, key=lambda pred_class:abs(pred_class - np.mean(X_pred_proba)))\n",
    "            predictions.append([X_pred])\n",
    "        return predictions\n",
    "    \n",
    "    def calculate_accuracy(self, y_true, y_pred):\n",
    "        if len(confusion_matrix(y_true, y_pred).ravel()) > 1:\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        else:\n",
    "            tp = confusion_matrix(y_true, y_pred).ravel()[0]\n",
    "            fp = 0\n",
    "            fn = 0\n",
    "            tn = 0\n",
    "        return (tp + tn) / (tp + tn + fp + fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is obtained from [Weka Data Sets](http://storm.cis.fordham.edu/~gweiss/data-mining/weka-data/weather.arff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = loadarff('dataset/weather.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(raw_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'sunny'</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>b'FALSE'</td>\n",
       "      <td>b'no'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'sunny'</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>b'TRUE'</td>\n",
       "      <td>b'no'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'overcast'</td>\n",
       "      <td>83.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>b'FALSE'</td>\n",
       "      <td>b'yes'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'rainy'</td>\n",
       "      <td>70.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>b'FALSE'</td>\n",
       "      <td>b'yes'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'rainy'</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>b'FALSE'</td>\n",
       "      <td>b'yes'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       outlook  temperature  humidity     windy    play\n",
       "0     b'sunny'         85.0      85.0  b'FALSE'   b'no'\n",
       "1     b'sunny'         80.0      90.0   b'TRUE'   b'no'\n",
       "2  b'overcast'         83.0      86.0  b'FALSE'  b'yes'\n",
       "3     b'rainy'         70.0      96.0  b'FALSE'  b'yes'\n",
       "4     b'rainy'         68.0      80.0  b'FALSE'  b'yes'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, preprocessing is needed because the current data types are not appropriate to be fed to the ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary_vector(data):\n",
    "    return pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, decode the string and boolean data as UTF-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, column in enumerate(['outlook', 'windy', 'play']):\n",
    "    data[column] = data[column].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the string data (`outlook` and `windy`) are converted to binary vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overcast</th>\n",
       "      <th>rainy</th>\n",
       "      <th>sunny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overcast  rainy  sunny\n",
       "0         0      0      1\n",
       "1         0      0      1\n",
       "2         1      0      0\n",
       "3         0      1      0\n",
       "4         0      1      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv_outlook = convert_to_binary_vector(data['outlook'])\n",
    "bv_outlook.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FALSE</th>\n",
       "      <th>TRUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FALSE  TRUE\n",
       "0      1     0\n",
       "1      0     1\n",
       "2      1     0\n",
       "3      1     0\n",
       "4      1     0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv_windy = convert_to_binary_vector(data['windy'])\n",
    "bv_windy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the former `outlook` and `windy` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_data = data.drop('outlook', 1).drop('windy', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process `play` data as categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_data['play'] = preproc_data['play'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the data with the binary vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overcast</th>\n",
       "      <th>rainy</th>\n",
       "      <th>sunny</th>\n",
       "      <th>FALSE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overcast  rainy  sunny  FALSE  TRUE  temperature  humidity play\n",
       "0         0      0      1      1     0         85.0      85.0   no\n",
       "1         0      0      1      0     1         80.0      90.0   no\n",
       "2         1      0      0      1     0         83.0      86.0  yes\n",
       "3         0      1      0      1     0         70.0      96.0  yes\n",
       "4         0      1      0      1     0         68.0      80.0  yes"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data = pd.concat([bv_outlook, bv_windy, preproc_data], axis=1)\n",
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `play` data as numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   play\n",
       "0     0\n",
       "1     0\n",
       "2     1\n",
       "3     1\n",
       "4     1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame({'play': preprocessed_data['play'].cat.codes})\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete label data from `X`, and process `X` as float data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessed_data.drop('play', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X.columns:\n",
    "    X[column] = X[column].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize real data (`temperature` and `humidity`) to 0-1 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['temperature', 'humidity']:\n",
    "    X[column] = (X[column] - min(X[column])) / (max(X[column]) - min(X[column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overcast</th>\n",
       "      <th>rainy</th>\n",
       "      <th>sunny</th>\n",
       "      <th>FALSE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.483871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overcast  rainy  sunny  FALSE  TRUE  temperature  humidity\n",
       "0       0.0    0.0    1.0    1.0   0.0     1.000000  0.645161\n",
       "1       0.0    0.0    1.0    0.0   1.0     0.761905  0.806452\n",
       "2       1.0    0.0    0.0    1.0   0.0     0.904762  0.677419\n",
       "3       0.0    1.0    0.0    1.0   0.0     0.285714  1.000000\n",
       "4       0.0    1.0    0.0    1.0   0.0     0.190476  0.483871"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process `y` (label) as float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn `X` and `y` to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final result of preprocessed `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "        1.        , 0.64516129],\n",
       "       [0.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.76190476, 0.80645161],\n",
       "       [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.9047619 , 0.67741935],\n",
       "       [0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "        0.28571429, 1.        ],\n",
       "       [0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "        0.19047619, 0.48387097],\n",
       "       [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.04761905, 0.16129032],\n",
       "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "        0.38095238, 0.96774194],\n",
       "       [0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "        0.23809524, 0.16129032],\n",
       "       [0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "        0.52380952, 0.48387097],\n",
       "       [0.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.52380952, 0.16129032],\n",
       "       [1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.38095238, 0.80645161],\n",
       "       [1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.80952381, 0.32258065],\n",
       "       [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.33333333, 0.83870968]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold-out split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data: 90% for training data and 10% for validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_val, y, y_val = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try training the data and predicting the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lunak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Lunak ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunak_ann = LunakArtificialNeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a hidden layer with two units and an output layer with one unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunak_ann.add(LunakDense(2, 'sigmoid', 7, 'uniform', use_bias=True, seed=5))\n",
    "lunak_ann.add(LunakDense(1, 'sigmoid', 2, 'uniform', use_bias=True, seed=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Lunak ANN using preprocessed `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples, validate on 2 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e6530ff71e474aa8e4ffa4303f73c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=6, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87773ca19dbb45a3b90e17e34fa6930a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=6, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2215e9c62ef34dd086cf3b0632c7d741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=6, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7399cf8e865d4f7c8d707c06643244f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=6, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8283c4828a9e4be0b6a25d9429d492f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=6, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2586476c064c46a2b12c87c0dc0660af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=6, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e0357e250f4ce3b83a2f75dd3381a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=6, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0ef81fc935444680636f01576271b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=6, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6d23e5292d45ca85b78bc8b98b1d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=6, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab093d57ab3449e0918a63584091cf2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 10', max=6, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lunak_ann.fit(X, y, epochs=10, momentum=0.001, lr=0.01, batch_size=2, val_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It yields prediction probabilities as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_proba = lunak_ann.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5100260265353183],\n",
       " [0.5098863792792119],\n",
       " [0.5099781754308265],\n",
       " [0.5098956803318473],\n",
       " [0.5101922973441301],\n",
       " [0.5098273720026467],\n",
       " [0.5098801583917586],\n",
       " [0.510178020640108],\n",
       " [0.5098564077998636],\n",
       " [0.5102136998191488],\n",
       " [0.509962999390932],\n",
       " [0.5101034248789686]]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted classes as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lunak_ann.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.initializers import RandomUniform\n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize ANN using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_ann = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add random uniform initializer for the initial weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = RandomUniform(minval=-0.05, maxval=0.05, seed=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a hidden layer with 2 units and an output layer with 1 unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_ann.add(Dense(2, activation='sigmoid', input_dim=7, use_bias=True, kernel_initializer=initializer))\n",
    "keras_ann.add(Dense(1, activation='sigmoid', use_bias=True, kernel_initializer=initializer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add stochastic gradient descent as optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ = keras.optimizers.SGD(momentum=0.001, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_ann.compile(loss='mean_squared_error', optimizer=optimizer_, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the data using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples, validate on 2 samples\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2498 - acc: 0.6667 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 524us/step - loss: 0.2492 - acc: 0.6667 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 359us/step - loss: 0.2484 - acc: 0.6667 - val_loss: 0.2501 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 421us/step - loss: 0.2478 - acc: 0.6667 - val_loss: 0.2501 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 568us/step - loss: 0.2472 - acc: 0.6667 - val_loss: 0.2501 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 346us/step - loss: 0.2468 - acc: 0.6667 - val_loss: 0.2502 - val_acc: 0.5000\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 338us/step - loss: 0.2463 - acc: 0.6667 - val_loss: 0.2502 - val_acc: 0.5000\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2456 - acc: 0.6667 - val_loss: 0.2502 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 743us/step - loss: 0.2451 - acc: 0.6667 - val_loss: 0.2503 - val_acc: 0.5000\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 673us/step - loss: 0.2447 - acc: 0.6667 - val_loss: 0.2504 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9988257518>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_ann.fit(X, y, epochs=10, batch_size=2, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51846087],\n",
       "       [0.51847076],\n",
       "       [0.5184803 ],\n",
       "       [0.5184764 ],\n",
       "       [0.5183501 ],\n",
       "       [0.5185053 ],\n",
       "       [0.5184343 ],\n",
       "       [0.51839614],\n",
       "       [0.51846385],\n",
       "       [0.51843315],\n",
       "       [0.51841855],\n",
       "       [0.5183843 ]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_ann.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fel semangat ya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responsibilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Felix Limanta (13515065)**: Layer and model implementation, debugging, Keras exploration, writing report\n",
    "\n",
    "**Holy Lovenia (13515113)**: Layer and model implementation, debugging, Keras exploration, writing report\n",
    "\n",
    "**Agus Gunawan (13515143)**: Layer and model implementation, debugging, Keras exploration, writing report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
